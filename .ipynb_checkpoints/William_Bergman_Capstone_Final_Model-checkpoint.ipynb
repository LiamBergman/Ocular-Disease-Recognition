{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41829415-1acd-4a69-992c-425a056acb9b",
   "metadata": {},
   "source": [
    "# Transfer Learning for Fundus Image Classification using ResNet50\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470d61f-f777-4aad-b600-cd267c8e7689",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is the fourth in a series focused on classifying fundus images into one of three categories: Normal, Diabetic Retinopathy, and Other Disease. The previous notebooks covered:\n",
    "\n",
    "1. **Exploratory Data Analysis (EDA)**: Understanding the dataset and its properties.\n",
    "2. **Baseline Model**: Establishing simple models as a point of comparison.\n",
    "3. **Baseline CNN Model**: Implementing a Convolutional Neural Network (CNN) for the task.\n",
    "\n",
    "In this notebook, we aim to improve the performance of our classification model by leveraging a pre-trained ResNet50 model for transfer learning. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Load and preprocess the fundus image dataset.\n",
    "- Implement transfer learning using ResNet50.\n",
    "- Evaluate the performance of the model and compare it with the baseline models.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "    - 1.1 [Objectives](#Objectives)\n",
    "    - 1.2 [Dataset Overview](#Dataset-Overview)\n",
    "2. [Data Preprocessing](#Data-Preprocessing)\n",
    "    - 2.1 [Data Loading](#Data-Loading)\n",
    "    - 2.2 [Data Augmentation](#Data-Augmentation)\n",
    "3. [Transfer Learning with ResNet50](#Transfer-Learning-with-ResNet50)\n",
    "    - 3.1 [Model Architecture](#Model-Architecture)\n",
    "    - 3.2 [Model Compilation](#Model-Compilation)\n",
    "    - 3.3 [Training](#Training)\n",
    "4. [Model Evaluation](#Model-Evaluation)\n",
    "    - 4.1 [Performance Metrics](#Performance-Metrics)\n",
    "5. [Comparative Analysis](#Comparative-Analysis)\n",
    "6. [Conclusion](#Conclusion)\n",
    "    - 6.1 [Summary](#Summary)\n",
    "    - 6.2 [Future Work](#Future-Work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58f2d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Libraries for Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for Image Handling\n",
    "from PIL import Image\n",
    "\n",
    "# Libraries for Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries for Machine Learning\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, KFold\n",
    "\n",
    "# PyTorch and Related Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, SubsetRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Libraries for Progress Monitoring\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331f3ed-e337-4df4-adc0-f01a372231f5",
   "metadata": {},
   "source": [
    "## Data-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24d22f-71dc-47a3-85b4-19aeb7b0e48e",
   "metadata": {},
   "source": [
    "### Data-Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ba92d-7d27-4192-8a78-4c7b68d1b3ab",
   "metadata": {},
   "source": [
    "All fo the paramters for the model can be found here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a86fe34e-0e19-4ffc-9b1f-faae3ab2d7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Data Loading \n",
    "PATH_train_df = 'data/train_df.csv' #Training Data Path \n",
    "PATH_test_df = 'data/test_df.csv' #Testing Data Path \n",
    "PATH_imgaes = 'data/preprocessed_images' #Image Folder Path\n",
    "\n",
    "#Model Parameters\n",
    "eps = 10 #Epochs \n",
    "pl = 5 #Patience Limit\n",
    "bs = 32 #Batch Size\n",
    "dr = 0.4 #Dropout Rate\n",
    "lr = 0.001 #Learning Rate\n",
    "\n",
    "# Transformer Parameters\n",
    "randRot = 5 #Random Rotation in Degrees\n",
    "brJit = 0.2 #Brightness Jitter\n",
    "ctJit =0.2 #Contrast Jitter\n",
    "brFct = 1.2 #Brightness Factor\n",
    "ctFct = 1.2 #Contrast Factor\n",
    "\n",
    "#K-Fold Cross-Validation\n",
    "k = 5 #Number of splits\n",
    "kCriterion = nn.CrossEntropyLoss() #Kriterion... Get it?\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db665ab-e416-4f8b-8d0e-67c845a773b4",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4b3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataframes(train_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb69e1-e952-4eee-aa71-98068f87e03c",
   "metadata": {},
   "source": [
    "Defining a DataSet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c397d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset Class for loading Fundus images and labels\n",
    "class FundusDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {'D': 0, 'O': 1, 'N': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.df.loc[idx, 'filename'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label_str = self.df.loc[idx, 'Grouped-Label']\n",
    "        label = self.label_mapping[label_str]\n",
    "        label = torch.tensor(label)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ea359-9fa6-45ab-a3ad-526831ede0e0",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040706b3-8fc0-4eb5-9cf4-e3fde1283fa6",
   "metadata": {},
   "source": [
    "Below we are have a function that will adjust transform the images for training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "420f2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transforms():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(randRot),\n",
    "        transforms.ColorJitter(brightness=brJit, contrast=ctJit),\n",
    "        transforms.Lambda(lambda img: F.adjust_brightness(img, brightness_factor=brFct)),\n",
    "        transforms.Lambda(lambda img: F.adjust_contrast(img, contrast_factor=ctFct)),\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.Lambda(lambda img: F.adjust_brightness(img, brightness_factor=brFct)),\n",
    "        transforms.Lambda(lambda img: F.adjust_contrast(img, contrast_factor=ctFct)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    return transform, val_transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbe0be-ea01-43cb-8e44-a9222b9eff98",
   "metadata": {},
   "source": [
    "## Transfer Learning with ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b32230-f1ab-4939-ad5a-3c5b1a971fdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here we are loading the dataframes into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b061014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataloaders(train_df, test_df, root_dir, transform, val_transform, batch_size=bs):\n",
    "    train_dataset = FundusDataset(dataframe=train_df, root_dir=root_dir, transform=transform)\n",
    "    val_dataset = FundusDataset(dataframe=test_df, root_dir=root_dir, transform=val_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36314d-19ff-4c82-9c4a-b4a3ec8fb69b",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e59ad-5628-4fe6-98b9-2f9688a04fed",
   "metadata": {},
   "source": [
    "Here we can get the resnet50Model and set the 3 features for the final layer. \n",
    "<br> Initially we had tried a resnet18 model but switched to the larger model to try to generalize better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f8eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 3)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58ea99-a7f2-4946-af53-1fcf09e68a28",
   "metadata": {},
   "source": [
    "Set the device to use the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eec8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0281ff56-1202-4f59-babc-8891dbc66135",
   "metadata": {
    "tags": []
   },
   "source": [
    "Set the criterion and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc411fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loss_and_optimizer(model, learning_rate=lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42585bc7-edee-4085-80c5-8ebe5ad8ad48",
   "metadata": {},
   "source": [
    "Here we set the early stopping parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9df65dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_early_stopping():\n",
    "    return float('inf'), 0, pl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1afc05-e90c-4844-8cc0-8dec99f37ef9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Below is the loops for one training and one validation epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc68250-d4f4-4986-9757-37bd49f8f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_bar = tqdm(train_loader, desc=\"Batches\", leave=True)\n",
    "    \n",
    "    for i, (images, labels) in enumerate(batch_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Run the model on input data\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Collect all the true labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            \n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    return avg_loss, np.array(all_labels), np.array(all_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eba5f7-c179-4575-af4d-8f517e1e6a9b",
   "metadata": {},
   "source": [
    "Here we initiate the metrics to blank arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "554c18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_metrics():\n",
    "    return [], [], [], [], []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6af2a-23aa-40e0-8d31-ac7851cd4521",
   "metadata": {},
   "source": [
    "And here is a function to update the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9e63c9-83ee-42ea-ad9f-218fd1203410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def update_metrics(lists, new_values):\n",
    "    for lst, value in zip(lists, new_values):\n",
    "        lst.append(value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e42eb1-fa7e-44a9-bae8-4dac0f9adc0a",
   "metadata": {},
   "source": [
    "Here we are defining the layer that we are updating. \n",
    "#### Function Overview\n",
    "- **Parameters**:\n",
    "  - `model`: The pre-trained model to be modified.\n",
    "  - `num_ftrs`: The number of features coming into the newly added fully connected layer.\n",
    "  - `freeze_all`: Boolean flag to control whether all layers are frozen or not.\n",
    "\n",
    "- **Process**:\n",
    "  1. Adds a new sequential block containing a fully connected layer, ReLU activation, dropout, and a final fully connected layer to output 3 classes.\n",
    "  2. Replaces the existing `fc` layer in the model with this new sequential block.\n",
    "  3. By default, freezes all parameters in the model to disable backpropagation.\n",
    "  4. Optionally, unfreezes the parameters in `layer4` and the new fully connected layer for fine-tuning.#### Function Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffdccd60-ccf6-496a-8ed2-a340b375ef52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modify_and_freeze_model(model, num_ftrs, freeze_all=True):\n",
    "    new_layers = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dr),\n",
    "        nn.Linear(256, 3)\n",
    "    )\n",
    "    model.fc = new_layers\n",
    "    \n",
    "    # Freezing all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreezing layers from layer4 onwards\n",
    "    if not freeze_all:\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1ec20f-a557-4904-8c0d-9e9703baebe0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Compilation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f013aa8-b65b-43ea-be08-b5f5186bd559",
   "metadata": {},
   "source": [
    "Here we have the function to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e3faa0c-064a-47c0-be32-e84a12fdf1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=eps, patience_limit=pl):\n",
    "    \n",
    "    best_val_loss, patience_counter, patience_limit = init_early_stopping()\n",
    "    train_f1, train_recall, train_accuracy, val_f1, val_recall = init_metrics()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Starting Epoch {epoch+1}\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {train_loss:.4f}\")\n",
    "        \n",
    "        val_loss, val_labels, val_preds = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Compute the metrics\n",
    "        f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "        accuracy = accuracy_score(val_labels, val_preds)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f}, F1: {f1:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        print(f\"Patience Counter: {patience_counter}\")\n",
    "        \n",
    "        if patience_counter >= patience_limit:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ea0b4-fa31-4e9d-a5ec-00ae7d7999d3",
   "metadata": {},
   "source": [
    "We are initializing all of the paramters required before running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55974c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize everything\n",
    "train_df, test_df = load_dataframes(PATH_train_df, PATH_test_df)\n",
    "transform, val_transform = get_transforms()\n",
    "train_loader, val_loader = get_dataloaders(train_df, test_df, PATH_imgaes, transform, val_transform)\n",
    "model = get_model()\n",
    "model = modify_and_freeze_model(model, model.fc.in_features)\n",
    "device = get_device()\n",
    "model = model.to(device)\n",
    "criterion, optimizer = get_loss_and_optimizer(model)\n",
    "best_val_loss, patience_counter, patience_limit = init_early_stopping()\n",
    "train_f1, train_recall, train_accuracy, val_f1, val_recall = init_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7743b-612a-4109-89ac-fe56a2f261f7",
   "metadata": {},
   "source": [
    "Quick model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d54774e9-db72-4e81-82f6-1c1f44408288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the model\n",
    "# train_model(model, train_loader, val_loader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ff969-8720-4832-af97-8d4b318b10be",
   "metadata": {},
   "source": [
    "This is for the K-Fold Validation logic.\n",
    "#### Function Overview\n",
    "- **Parameters**:\n",
    "  - `k`: Number of folds for the K-Fold Cross-Validation.\n",
    "  - `full_dataset`: The complete dataset to be split into training and validation sets.\n",
    "  - `model_func`: Function to initialize the model architecture.\n",
    "  - `kCriterion`: Loss criterion to use during training.\n",
    "  - `optimizer_func`: Function to initialize the optimizer.\n",
    "  - `device`: Computing device (CPU or GPU).\n",
    "  - `epochs`: Number of training epochs (default is set to the value of `eps`).\n",
    "\n",
    "- **Process**:\n",
    "  1. Initializes K-Fold splitting.\n",
    "  2. Iterates through each fold, creating training and validation subsets.\n",
    "  3. Initializes the model, optimizer, and other settings for each fold.\n",
    "  4. Trains the model using the `train_model` function.\n",
    "  5. Validates the model on the validation subset and computes metrics.\n",
    "\n",
    "- **Output**:\n",
    "    - Returns a list containing validation loss, true labels, and predicted labels for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76af6720-cd0d-4913-a045-2ed46f99b1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def k_fold_train_model(k, full_dataset, model_func, kCriterion, optimizer_func, device, epochs=eps):\n",
    "    kf = KFold(n_splits=k)\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset)):\n",
    "        print(f\"Starting Fold {fold+1}\")\n",
    "        \n",
    "        # Create train and validation data loaders\n",
    "        train_subsampler = SubsetRandomSampler(train_idx)\n",
    "        val_subsampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(full_dataset, batch_size=bs, sampler=train_subsampler)\n",
    "        val_loader = DataLoader(full_dataset, batch_size=bs, sampler=val_subsampler)\n",
    "        \n",
    "        # Initialize model, optimizer, and other settings for each fold\n",
    "        model = model_func().to(device)\n",
    "        criterion = kCriterion\n",
    "        optimizer = optimizer_func(model)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs)\n",
    "        \n",
    "        # Compute validation metrics\n",
    "        val_loss, val_labels, val_preds = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        fold_results.append((val_loss, val_labels, val_preds))\n",
    "        print(f\"Fold {fold+1} - Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "    return fold_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7f463-8e64-4fb2-8959-d2e4b5fbce5b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e2758-167d-4f05-989b-2f734ccaf843",
   "metadata": {},
   "source": [
    "This is where the fun begins! And Waiting. \n",
    "<br> We start training the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "974d08b4-377d-4f0f-831c-27a013c92f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold 1\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:18<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.0458\n",
      "Epoch 1 - Validation Loss: 0.9839, F1: 0.5076, Recall: 0.5230, Accuracy: 0.5230\n",
      "Patience Counter: 0\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:14<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.9368\n",
      "Epoch 2 - Validation Loss: 0.9049, F1: 0.5530, Recall: 0.5591, Accuracy: 0.5591\n",
      "Patience Counter: 0\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:10<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.8989\n",
      "Epoch 3 - Validation Loss: 0.9425, F1: 0.4907, Recall: 0.5103, Accuracy: 0.5103\n",
      "Patience Counter: 1\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:10<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.8702\n",
      "Epoch 4 - Validation Loss: 0.9233, F1: 0.5604, Recall: 0.5679, Accuracy: 0.5679\n",
      "Patience Counter: 2\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:10<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.8519\n",
      "Epoch 5 - Validation Loss: 0.9407, F1: 0.5239, Recall: 0.5376, Accuracy: 0.5376\n",
      "Patience Counter: 3\n",
      "Starting Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:17<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 0.8256\n",
      "Epoch 6 - Validation Loss: 0.8888, F1: 0.5771, Recall: 0.5816, Accuracy: 0.5816\n",
      "Patience Counter: 0\n",
      "Starting Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:12<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 0.7978\n",
      "Epoch 7 - Validation Loss: 0.9565, F1: 0.5329, Recall: 0.5415, Accuracy: 0.5415\n",
      "Patience Counter: 1\n",
      "Starting Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:12<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 0.7773\n",
      "Epoch 8 - Validation Loss: 0.9001, F1: 0.5853, Recall: 0.5914, Accuracy: 0.5914\n",
      "Patience Counter: 2\n",
      "Starting Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:11<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 0.7518\n",
      "Epoch 9 - Validation Loss: 0.8768, F1: 0.6013, Recall: 0.6012, Accuracy: 0.6012\n",
      "Patience Counter: 0\n",
      "Starting Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:11<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 0.7275\n",
      "Epoch 10 - Validation Loss: 0.9627, F1: 0.5757, Recall: 0.5806, Accuracy: 0.5806\n",
      "Patience Counter: 1\n",
      "Fold 1 - Validation Loss: 0.9594\n",
      "Starting Fold 2\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:10<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.0543\n",
      "Epoch 1 - Validation Loss: 1.1453, F1: 0.4290, Recall: 0.4692, Accuracy: 0.4692\n",
      "Patience Counter: 0\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:11<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.9519\n",
      "Epoch 2 - Validation Loss: 0.9242, F1: 0.5407, Recall: 0.5533, Accuracy: 0.5533\n",
      "Patience Counter: 0\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:11<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.9159\n",
      "Epoch 3 - Validation Loss: 0.8979, F1: 0.5610, Recall: 0.5670, Accuracy: 0.5670\n",
      "Patience Counter: 0\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:11<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.8721\n",
      "Epoch 4 - Validation Loss: 0.8781, F1: 0.5773, Recall: 0.5787, Accuracy: 0.5787\n",
      "Patience Counter: 0\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:10<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.8445\n",
      "Epoch 5 - Validation Loss: 0.9053, F1: 0.5614, Recall: 0.5679, Accuracy: 0.5679\n",
      "Patience Counter: 1\n",
      "Starting Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:28<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 0.8288\n",
      "Epoch 6 - Validation Loss: 0.8588, F1: 0.5864, Recall: 0.5855, Accuracy: 0.5855\n",
      "Patience Counter: 0\n",
      "Starting Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:44<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 0.8055\n",
      "Epoch 7 - Validation Loss: 0.8709, F1: 0.5943, Recall: 0.5943, Accuracy: 0.5943\n",
      "Patience Counter: 1\n",
      "Starting Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:43<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 0.7700\n",
      "Epoch 8 - Validation Loss: 0.9812, F1: 0.5419, Recall: 0.5533, Accuracy: 0.5533\n",
      "Patience Counter: 2\n",
      "Starting Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:23<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 0.7516\n",
      "Epoch 9 - Validation Loss: 0.8789, F1: 0.5746, Recall: 0.5806, Accuracy: 0.5806\n",
      "Patience Counter: 3\n",
      "Starting Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:19<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 0.7353\n",
      "Epoch 10 - Validation Loss: 0.8840, F1: 0.5724, Recall: 0.5777, Accuracy: 0.5777\n",
      "Patience Counter: 4\n",
      "Fold 2 - Validation Loss: 0.8866\n",
      "Starting Fold 3\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:36<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.0513\n",
      "Epoch 1 - Validation Loss: 0.9965, F1: 0.4734, Recall: 0.4907, Accuracy: 0.4907\n",
      "Patience Counter: 0\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:38<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.9439\n",
      "Epoch 2 - Validation Loss: 0.9697, F1: 0.5409, Recall: 0.5494, Accuracy: 0.5494\n",
      "Patience Counter: 0\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:34<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.8977\n",
      "Epoch 3 - Validation Loss: 0.9378, F1: 0.5511, Recall: 0.5533, Accuracy: 0.5533\n",
      "Patience Counter: 0\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:23<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.8710\n",
      "Epoch 4 - Validation Loss: 0.9261, F1: 0.5869, Recall: 0.5885, Accuracy: 0.5885\n",
      "Patience Counter: 0\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:27<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.8380\n",
      "Epoch 5 - Validation Loss: 0.9440, F1: 0.5640, Recall: 0.5660, Accuracy: 0.5660\n",
      "Patience Counter: 1\n",
      "Starting Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:36<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 0.8194\n",
      "Epoch 6 - Validation Loss: 0.8985, F1: 0.5871, Recall: 0.5885, Accuracy: 0.5885\n",
      "Patience Counter: 0\n",
      "Starting Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:19<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 0.8030\n",
      "Epoch 7 - Validation Loss: 0.9495, F1: 0.5667, Recall: 0.5699, Accuracy: 0.5699\n",
      "Patience Counter: 1\n",
      "Starting Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:39<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 0.7683\n",
      "Epoch 8 - Validation Loss: 0.9221, F1: 0.6002, Recall: 0.6012, Accuracy: 0.6012\n",
      "Patience Counter: 2\n",
      "Starting Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:40<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 0.7594\n",
      "Epoch 9 - Validation Loss: 0.9377, F1: 0.5641, Recall: 0.5709, Accuracy: 0.5709\n",
      "Patience Counter: 3\n",
      "Starting Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:22<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 0.7405\n",
      "Epoch 10 - Validation Loss: 0.9209, F1: 0.5919, Recall: 0.5914, Accuracy: 0.5914\n",
      "Patience Counter: 4\n",
      "Fold 3 - Validation Loss: 0.9274\n",
      "Starting Fold 4\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:17<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.0553\n",
      "Epoch 1 - Validation Loss: 1.0037, F1: 0.4413, Recall: 0.4883, Accuracy: 0.4883\n",
      "Patience Counter: 0\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:20<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.9639\n",
      "Epoch 2 - Validation Loss: 0.9297, F1: 0.5329, Recall: 0.5411, Accuracy: 0.5411\n",
      "Patience Counter: 0\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:25<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.8947\n",
      "Epoch 3 - Validation Loss: 0.8868, F1: 0.5903, Recall: 0.5890, Accuracy: 0.5890\n",
      "Patience Counter: 0\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:24<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.8789\n",
      "Epoch 4 - Validation Loss: 0.8990, F1: 0.5804, Recall: 0.5783, Accuracy: 0.5783\n",
      "Patience Counter: 1\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:16<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.8479\n",
      "Epoch 5 - Validation Loss: 0.8875, F1: 0.5711, Recall: 0.5724, Accuracy: 0.5724\n",
      "Patience Counter: 2\n",
      "Starting Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:13<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 0.8212\n",
      "Epoch 6 - Validation Loss: 0.8518, F1: 0.5969, Recall: 0.5959, Accuracy: 0.5959\n",
      "Patience Counter: 0\n",
      "Starting Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:13<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 0.7834\n",
      "Epoch 7 - Validation Loss: 0.8630, F1: 0.5772, Recall: 0.5783, Accuracy: 0.5783\n",
      "Patience Counter: 1\n",
      "Starting Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:13<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 0.7596\n",
      "Epoch 8 - Validation Loss: 0.8799, F1: 0.5897, Recall: 0.5969, Accuracy: 0.5969\n",
      "Patience Counter: 2\n",
      "Starting Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:13<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 0.7482\n",
      "Epoch 9 - Validation Loss: 0.8963, F1: 0.5707, Recall: 0.5695, Accuracy: 0.5695\n",
      "Patience Counter: 3\n",
      "Starting Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:13<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 0.7096\n",
      "Epoch 10 - Validation Loss: 0.8910, F1: 0.5917, Recall: 0.5959, Accuracy: 0.5959\n",
      "Patience Counter: 4\n",
      "Fold 4 - Validation Loss: 0.8699\n",
      "Starting Fold 5\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:13<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.0534\n",
      "Epoch 1 - Validation Loss: 1.2074, F1: 0.4167, Recall: 0.4687, Accuracy: 0.4687\n",
      "Patience Counter: 0\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:13<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.9613\n",
      "Epoch 2 - Validation Loss: 0.8917, F1: 0.5799, Recall: 0.5793, Accuracy: 0.5793\n",
      "Patience Counter: 0\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:15<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.9096\n",
      "Epoch 3 - Validation Loss: 0.8964, F1: 0.5613, Recall: 0.5636, Accuracy: 0.5636\n",
      "Patience Counter: 1\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:28<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.8805\n",
      "Epoch 4 - Validation Loss: 0.9048, F1: 0.5674, Recall: 0.5665, Accuracy: 0.5665\n",
      "Patience Counter: 2\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:32<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.8544\n",
      "Epoch 5 - Validation Loss: 0.8392, F1: 0.6125, Recall: 0.6115, Accuracy: 0.6115\n",
      "Patience Counter: 0\n",
      "Starting Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:27<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 0.8244\n",
      "Epoch 6 - Validation Loss: 0.9258, F1: 0.5873, Recall: 0.5871, Accuracy: 0.5871\n",
      "Patience Counter: 1\n",
      "Starting Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:27<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 0.8136\n",
      "Epoch 7 - Validation Loss: 0.8635, F1: 0.5828, Recall: 0.5822, Accuracy: 0.5822\n",
      "Patience Counter: 2\n",
      "Starting Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:26<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 0.7800\n",
      "Epoch 8 - Validation Loss: 0.8776, F1: 0.5912, Recall: 0.5930, Accuracy: 0.5930\n",
      "Patience Counter: 3\n",
      "Starting Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:29<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 0.7673\n",
      "Epoch 9 - Validation Loss: 0.8384, F1: 0.6087, Recall: 0.6096, Accuracy: 0.6096\n",
      "Patience Counter: 0\n",
      "Starting Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 128/128 [03:24<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 0.7287\n",
      "Epoch 10 - Validation Loss: 0.8450, F1: 0.6078, Recall: 0.6067, Accuracy: 0.6067\n",
      "Patience Counter: 1\n",
      "Fold 5 - Validation Loss: 0.8455\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Training Data for K-Folds\n",
    "full_dataset = FundusDataset(dataframe=train_df, root_dir=PATH_imgaes, transform=transform)\n",
    "\n",
    "# Function to create a new model\n",
    "def create_model():\n",
    "    base_model = get_model()\n",
    "    return modify_and_freeze_model(base_model, base_model.fc.in_features, freeze_all=False)\n",
    "\n",
    "# Function to create a new optimizer\n",
    "def create_optimizer(model):\n",
    "    return optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Run 5-fold cross-validation\n",
    "k_fold_results = k_fold_train_model(k, full_dataset, create_model, kCriterion, create_optimizer, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5d60f-5c8f-45d3-8a8a-3bc53c29f897",
   "metadata": {},
   "source": [
    "### K-Fold Validation Metrics for the Final Model\n",
    "\n",
    "The final model was trained and validated using 5-Fold Cross-Validation. Here are the validation metrics obtained at the 10th epoch for each fold:\n",
    "\n",
    "#### Fold 1\n",
    "- **Training Loss**: 0.7275\n",
    "- **Validation Loss**: 0.9594\n",
    "- **F1 Score**: 0.5757\n",
    "- **Recall**: 0.5806\n",
    "- **Accuracy**: 0.5806\n",
    "\n",
    "#### Fold 2\n",
    "- **Training Loss**: 0.7353\n",
    "- **Validation Loss**: 0.8866\n",
    "- **F1 Score**: 0.5724\n",
    "- **Recall**: 0.5777\n",
    "- **Accuracy**: 0.5777\n",
    "\n",
    "#### Fold 3\n",
    "- **Training Loss**: 0.7405\n",
    "- **Validation Loss**: 0.9274\n",
    "- **F1 Score**: 0.5919\n",
    "- **Recall**: 0.5914\n",
    "- **Accuracy**: 0.5914\n",
    "\n",
    "#### Fold 4\n",
    "- **Training Loss**: 0.7096\n",
    "- **Validation Loss**: 0.8699\n",
    "- **F1 Score**: 0.5917\n",
    "- **Recall**: 0.5959\n",
    "- **Accuracy**: 0.5959\n",
    "\n",
    "#### Fold 5\n",
    "- **Training Loss**: 0.7287\n",
    "- **Validation Loss**: 0.8455\n",
    "- **F1 Score**: 0.6078\n",
    "- **Recall**: 0.6067\n",
    "- **Accuracy**: 0.6067\n",
    "\n",
    "#### Observations\n",
    "- F1 Score, Recall, and Accuracy show variations across the folds, with Fold 5 demonstrating the best performance.\n",
    "- The Validation Loss also shows some fluctuations across the folds, hinting at the model's sensitivity to the data distribution.\n",
    "\n",
    "These K-Fold metrics provide a comprehensive view of the model's robustness and generalization capabilities across different subsets of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb7539-a670-4579-8773-59e1ac9e9819",
   "metadata": {},
   "source": [
    "We save the model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b099fc7-1e9b-4299-8fa6-8bd7c314bf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'res50Fundus.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1fd5f-5da9-46ca-8b47-44600f7b944a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e77cc-eebb-46fe-ae7c-877120f60df1",
   "metadata": {},
   "source": [
    "Load in the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa954f8c-e119-4a84-ad40-62cd338a0af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming test_df is your test DataFrame and FundusDataset is your custom dataset class\n",
    "test_dataset = FundusDataset(test_df, PATH_imgaes, transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e3d30-8ab8-4d5c-a629-c9e3137e747e",
   "metadata": {},
   "source": [
    "Load up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4155bfc-ec36-48e5-971b-8d33c366bd71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize the model architecture\n",
    "model = get_model()\n",
    "\n",
    "# Modify and optionally freeze model layers\n",
    "num_ftrs = model.fc.in_features  # Or the number of features that your model's fc layer expects\n",
    "model = modify_and_freeze_model(model, num_ftrs, freeze_all=False)  # Set freeze_all based on your training setup\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(torch.load('res50Fundus.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7829d76-7edf-41a7-a0bd-917165089b6f",
   "metadata": {},
   "source": [
    "Ensure that the GPU is running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abdcab1e-cf18-43ff-8123-ef9c83fd28b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Move the model to the device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60322d-7bd2-4de1-8527-f77f5702a546",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752177b-d7b6-4a62-92eb-28934410d85b",
   "metadata": {},
   "source": [
    "Check the performance metrics on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a87996c6-2bd6-4103-a78b-38a8028a64a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.20394488135985972\n",
      "Recall: 0.33620015637216577\n",
      "Accuracy: 0.33620015637216577\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "recall = recall_score(true_labels, pred_labels, average='weighted')\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd51aed-ec2b-4d49-84ae-96012a4fe29e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f38f74-fb80-4b87-91b3-892493447c2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Final Model\n",
    "- **F1 Score**: 0.204\n",
    "- **Recall**: 0.336\n",
    "- **Accuracy**: 0.336\n",
    "\n",
    "#### Augmented Baseline CNN Model\n",
    "- **F1 Score**: 0.325\n",
    "- **Recall**: 0.334\n",
    "- **Accuracy**: 0.334\n",
    "\n",
    "#### Initial Baseline CNN Model\n",
    "- **F1 Score**: 0.168\n",
    "- **Recall**: 0.333\n",
    "- **Accuracy**: 0.333\n",
    "\n",
    "#### Observations\n",
    "- The F1 Score of the final model (0.204) is better than the initial baseline (0.168) but worse than the previous baseline (0.325).\n",
    "- Recall and Accuracy show a slight increase across all models, with the final model marginally outperforming the baselines.\n",
    "\n",
    "The metrics indicate a mixed performance. While the final model improves upon the initial baseline in terms of F1 Score, it falls short of the performance achieved by the previous baseline model. Further investigation is needed to understand the factors contributing to these variations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9da7fe-e8ef-4827-a9aa-2c7413e5bcdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Further Analysis and Next Steps\n",
    "\n",
    "#### Analyzing Metrics\n",
    "- **Comparison with Baselines**: The final model's F1 score is lower than the previous baseline but higher than the initial baseline. This indicates that some changes may have led to a decrease in performance compared to the previous baseline.\n",
    "\n",
    "#### Potential Causes\n",
    "- **Model Complexity**: The model may be either too complex or too simple to capture the underlying patterns in the data effectively.\n",
    "    - More experimenting with adding or removing layers and neurons may need to be done. Techniques like dropout or regularization to control overfitting were used but perhaps not to the best paramters.\n",
    "- **Hyperparameter Tuning**: The choice of hyperparameters like learning rate, dropout rate, etc., could be suboptimal.\n",
    "    - Use hyperparameter optimization techniques such as grid search or random search to systematically explore the hyperparameter space and identify the best-performing settings. This was done in the previous notebook but clearly does not translate to this model.\n",
    "- **Data Augmentation**: The transformations applied might not be beneficial for this specific task, or additional augmentations may be needed.\n",
    "<br>-Evaluate the effectiveness of each augmentation technique through systematic removal of some of the augmentations. I will need to experiment with different types and combinations of data augmentations to identify the most beneficial set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cef8da-6df5-4879-b19a-db8093912b36",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3eb72f-a54c-46b7-83b2-c2527c94aaa8",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf684b-f4dd-4d90-89a2-14639c1923d5",
   "metadata": {},
   "source": [
    "The final model showed improvement over the initial baseline but performed less optimally compared to the previous baseline with the K-Fold validation indicating variability in performance metrics.\n",
    "<br>Given the current metrics and observations, further diagnostic analysis and model refinement are needed. A systematic approach to identifying bottlenecks and areas for improvement will be essential for enhancing the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43752c9a-9f64-464f-8c85-451bdc9aec29",
   "metadata": {},
   "source": [
    "### Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba346a8a-3ec2-4e93-80fb-30abc542fe16",
   "metadata": {},
   "source": [
    "- **Hyperparameter Optimization**: Employ techniques like grid search or random search for hyperparameter tuning.\n",
    "- **Ensemble Methods**: Consider using ensemble methods to combine the strengths of multiple models.\n",
    "- **Data Resampling**: Implement oversampling or undersampling techniques to balance the classes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
